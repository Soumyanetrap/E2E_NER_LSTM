{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11513it [00:00, 34122.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>intent</th>\n",
       "      <th>action</th>\n",
       "      <th>paths</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>event</td>\n",
       "      <td>calendar_set</td>\n",
       "      <td>set</td>\n",
       "      <td>[audio-1501754435.flac, audio-1501407267-heads...</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i need an event three days from now scheduled ...</td>\n",
       "      <td>calendar_set</td>\n",
       "      <td>set</td>\n",
       "      <td>[audio-1498578293.flac, audio-1490262086-heads...</td>\n",
       "      <td>[O, O, O, O, date, date, date, date, O, O, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turn up</td>\n",
       "      <td>audio_volume_up</td>\n",
       "      <td>volume_up</td>\n",
       "      <td>[audio-1490183568-headset.flac, audio-14901835...</td>\n",
       "      <td>[O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brighten the lights a little bit</td>\n",
       "      <td>iot_hue_lightup</td>\n",
       "      <td>hue_lightup</td>\n",
       "      <td>[audio-1490019123-headset.flac, audio-14900191...</td>\n",
       "      <td>[O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what's the current weather</td>\n",
       "      <td>weather_query</td>\n",
       "      <td>query</td>\n",
       "      <td>[audio-1501754622.flac]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript           intent  \\\n",
       "0                                              event     calendar_set   \n",
       "1  i need an event three days from now scheduled ...     calendar_set   \n",
       "2                                            turn up  audio_volume_up   \n",
       "3                   brighten the lights a little bit  iot_hue_lightup   \n",
       "4                         what's the current weather    weather_query   \n",
       "\n",
       "        action                                              paths  \\\n",
       "0          set  [audio-1501754435.flac, audio-1501407267-heads...   \n",
       "1          set  [audio-1498578293.flac, audio-1490262086-heads...   \n",
       "2    volume_up  [audio-1490183568-headset.flac, audio-14901835...   \n",
       "3  hue_lightup  [audio-1490019123-headset.flac, audio-14900191...   \n",
       "4        query                            [audio-1501754622.flac]   \n",
       "\n",
       "                                            entities  \n",
       "0                                                [O]  \n",
       "1  [O, O, O, O, date, date, date, date, O, O, per...  \n",
       "2                                             [O, O]  \n",
       "3                                 [O, O, O, O, O, O]  \n",
       "4                                    [O, O, O, O, O]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../../dataset/slurp/dataset/slurp/'\n",
    "\n",
    "#'transcript','intent','action','paths', 'entities'\n",
    "with open(os.path.join(file_path,'train.jsonl')) as f:\n",
    "    entries = []\n",
    "    entity_type = []\n",
    "    for i, line in tqdm(enumerate(f)):\n",
    "        if i < 0: break\n",
    "        line = json.loads(line)\n",
    "        temp =[]\n",
    "        temp.append(line['sentence'])\n",
    "        temp.append(line['intent'])\n",
    "        temp.append(line['action'])\n",
    "        temp.append([path['file'] for path in line['recordings']])\n",
    "        entities = ['O' for _ in range(len(re.split(r\"[ \\-\\']\",line['sentence'])))]\n",
    "        for entity in line['entities']:\n",
    "            for ind in entity['span']:\n",
    "                    entities[ind] = entity['type']\n",
    "                    if entity['type'] not in entity_type:\n",
    "                         entity_type.append(entity['type'])\n",
    "        temp.append(entities)\n",
    "        entries.append(temp)\n",
    "\n",
    "df = pd.DataFrame(entries,columns=['transcript','intent','action','paths', 'entities'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(file_path,'train_data.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchaudio \n",
    "# from IPython.display import Audio\n",
    "\n",
    "# signal,rate = torchaudio.load('../../dataset/slurp/scripts/audio/slurp_real/audio-1500979433.flac')\n",
    "# Audio(signal,rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23132/23132 [00:00<00:00, 35170.65it/s]\n",
      "100%|██████████| 3118/3118 [00:00<00:00, 35686.85it/s]\n",
      "100%|██████████| 3793/3793 [00:00<00:00, 32098.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "dataset_path_base = '../../dataset/fluent_speech_commands_dataset/'\n",
    "\n",
    "def prep_data(train_df):\n",
    "    transcription_data = []\n",
    "    for i in tqdm(range(0,len(train_df))):\n",
    "        path = train_df.loc[i,'path']\n",
    "        true_transcription = train_df.loc[i,'transcription']\n",
    "        action = train_df.loc[i,'action']\n",
    "        object = train_df.loc[i,'object']\n",
    "        location = train_df.loc[i,'location']\n",
    "        labels = []\n",
    "        for v in true_transcription.split(\" \"):\n",
    "            if(v == object):\n",
    "                labels.append('object')\n",
    "            elif(v == location):\n",
    "                labels.append('location')\n",
    "            else:\n",
    "                labels.append('O')\n",
    "        transcription_data.append([path,true_transcription,action,','.join(labels)])\n",
    "\n",
    "    transcription_df = pd.DataFrame(transcription_data,columns=['path','transcription','action','labels'])\n",
    "    return transcription_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(dataset_path_base+'/data','train_data.csv'))\n",
    "transcription_df = prep_data(train_df)\n",
    "transcription_df.to_csv(os.path.join(dataset_path_base+'/data','train_labeled.csv'), index=False)\n",
    "\n",
    "valid_df = pd.read_csv(os.path.join(dataset_path_base+'/data','valid_data.csv'))\n",
    "transcription_df = prep_data(valid_df)\n",
    "transcription_df.to_csv(os.path.join(dataset_path_base+'/data','valid_labeled.csv'), index=False)\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(dataset_path_base+'/data','test_data.csv'))\n",
    "transcription_df = prep_data(test_df)\n",
    "transcription_df.to_csv(os.path.join(dataset_path_base+'/data','test_labeled.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Device 0: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n",
      "Device 1: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n",
      "Device 2: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n",
      "Device 3: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n",
      "Device 4: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n",
      "Device 5: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n",
      "Device 6: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n",
      "Device 7: Tesla V100-SXM2-32GB\n",
      "Total Memory: 31.75 GB\n",
      "Used Memory: 0.00 GB\n",
      "Free Memory: 0.00 MB\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available CUDA devices\n",
    "    num_cuda_devices = torch.cuda.device_count()\n",
    "    print(num_cuda_devices)\n",
    "    # Loop through each CUDA device\n",
    "    for device_idx in range(num_cuda_devices):\n",
    "        device = torch.device(f'cuda:{device_idx}')\n",
    "        device_name = torch.cuda.get_device_name(device)\n",
    "        print(f\"Device {device_idx}: {device_name}\")\n",
    "\n",
    "        # Get device's memory information\n",
    "        total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "        free_memory = torch.cuda.memory_reserved(device) - torch.cuda.memory_allocated(device)\n",
    "        used_memory = torch.cuda.memory_allocated(device)\n",
    "\n",
    "        # Convert memory values to human-readable format\n",
    "        total_memory = total_memory / (1024**3)  # Convert bytes to gigabytes\n",
    "        free_memory = free_memory / (1024**2)\n",
    "        used_memory = used_memory / (1024**3)\n",
    "\n",
    "        print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "        print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "        print(f\"Free Memory: {free_memory:.2f} MB\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print('No CUDA devices (GPUs) available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr-ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
